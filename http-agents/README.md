|&nbsp;&nbsp;&nbsp;&nbsp;_Folder&nbsp;&nbsp;Name_&nbsp;&nbsp;&nbsp;&nbsp;| _Description of Contents_
|:----------------|--------------------------------------------------------------------------------------------------------------------------------------------------------
| [badbotlist-user-agents](badbotlist-user-agents.conf) |  [Apache HTTP Server](https://httpd.apache.org) configuration to reject requests containing bad user agents <https://gist.github.com/idea34/1377722> 
| [chrome-user-agents](chrome-user-agents.txt) |  [Google Chrome](https://chrome.google.com) user agent strings 
| [common-user-agents](common-user-agents.txt) |  common user agent strings 
| [dotdotpwn-user-agents](dotdotpwn-user-agents.txt) | [dotdotpwn](https://github.com/wireghoul/dotdotpwn "DotDotPwn - The Directory Traversal Fuzzer") user agents <https://github.com/wireghoul/dotdotpwn/blob/master/DotDotPwn/User-Agents.txt>
| [firefox-user-agents](firefox-user-agents.txt) |  [Mozilla FireFox](https://mozilla.org/firefox) user agent strings 
| [http-user-agents](http-user-agents.txt) |  user agent values from various browsers and other HTTP clients 
| [msie-user-agents](msie-user-agents.txt) |  [Microsoft Internet Explorer](https://windows.microsoft.com/internet-explorer) user agent strings 
| [robots-user-agents](robots-user-agents.txt) |  User agent list taken from [Robots Database](http://robotstxt.org/db.html "The Web Robots Pages") 
| [safari-user-agents](safari-user-agents.txt) |  [Apple Safari](https://apple.com/safari) user agent strings 
| [user-agents-objects](user-agents-objects.js) |  <https://github.com/lancedikson/bowser/blob/master/src/useragents.js> 
| [webcrawler-robots-database](webcrawler-robots-database.txt) |  legacy `webcrawler.com` robots database 

* * *

